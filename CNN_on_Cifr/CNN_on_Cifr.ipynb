{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWBmZ8TMD0Gn",
        "colab_type": "text"
      },
      "source": [
        "### CNN on CIFR Assignment:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ysdzDcqD0Gp",
        "colab_type": "text"
      },
      "source": [
        "1.  Please visit this link to access the state-of-art DenseNet code for reference - DenseNet - cifar10 notebook link\n",
        "2.  You need to create a copy of this and \"retrain\" this model to achieve 90+ test accuracy. \n",
        "3.  You cannot use Dense Layers (also called fully connected layers), or DropOut.\n",
        "4.  You MUST use Image Augmentation Techniques.\n",
        "5.  You cannot use an already trained model as a beginning points, you have to initilize as your own\n",
        "6.  You cannot run the program for more than 300 Epochs, and it should be clear from your log, that you have only used 300 Epochs\n",
        "7.  You cannot use test images for training the model.\n",
        "8.  You cannot change the general architecture of DenseNet (which means you must use Dense Block, Transition and Output blocks as mentioned in the code)\n",
        "9.  You are free to change Convolution types (e.g. from 3x3 normal convolution to Depthwise Separable, etc)\n",
        "10. You cannot have more than 1 Million parameters in total\n",
        "11. You are free to move the code from Keras to Tensorflow, Pytorch, MXNET etc. \n",
        "12. You can use any optimization algorithm you need. \n",
        "13. You can checkpoint your model and retrain the model from that checkpoint so that no need of training the model from first if you lost at any epoch while training. You can directly load that model and Train from that epoch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wVIx_KIigxPV",
        "colab": {}
      },
      "source": [
        "# import keras\n",
        "# from keras.datasets import cifar10\n",
        "# from keras.models import Model, Sequential\n",
        "# from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "# from keras.layers import Concatenate\n",
        "# from keras.optimizers import Adam\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UNHw6luQg3gc",
        "colab": {}
      },
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "\n",
        "# from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "# import tensorflow as tf\n",
        "#tf.config.gpu.set_per_process_memory_fraction(0.75)\n",
        "#tf.config.gpu.set_per_process_memory_growth(True)\n",
        "# config = tf.ConfigProto()\n",
        "# config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "# k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dsO_yGxcg5D8",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 85\n",
        "l = 6\n",
        "num_filter = 35\n",
        "compression = 1\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mB7o3zu1g6eT",
        "outputId": "7a8f57ce-5767-4818-a3f2-5342772617c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load CIFAR10 Data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM3PN7NeD6OM",
        "colab_type": "code",
        "outputId": "cbd2bb15-1bcc-4dbc-c7f2-3ebebdb0f840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbYEP2JgD6OP",
        "colab_type": "code",
        "outputId": "f26a3a7d-6867-4072-f29d-51568def9b35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8zviOxRKrNC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ee-sge5Kg7vr",
        "colab": {}
      },
      "source": [
        "# Dense Block\n",
        "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l): \n",
        "        BatchNorm = layers.BatchNormalization()(temp)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "## transition Block\n",
        "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    return avg\n",
        "\n",
        "#output layer\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    AvgPooling = layers.AveragePooling2D(pool_size=(3,3))(relu)\n",
        "    #flat = layers.Flatten()(AvgPooling)\n",
        "    #a=tf.keras.layers.Reshape((None,312,1), input_shape=(2,2,78))\n",
        "    #model=tf.reshape(flat,[None,312,1])\n",
        "    output = layers.Conv2D(10,(1,1),strides=(1,1),activation='softmax',padding='valid')(AvgPooling)\n",
        "    flat = layers.Flatten()(output)\n",
        "\n",
        "    return flat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "anPCpQWhhGb7",
        "colab": {}
      },
      "source": [
        "#https://www.kaggle.com/genesis16/densenet-93-accuracy\n",
        "input = layers.Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1kFh7pdxhNtT",
        "outputId": "ae143251-5b0c-4251-e93a-4e82609829aa",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 32, 32, 35)   945         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 32, 32, 35)   140         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 32, 32, 35)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 32, 32, 35)   11025       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_51 (Dropout)            (None, 32, 32, 35)   0           conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 32, 32, 70)   0           conv2d_53[0][0]                  \n",
            "                                                                 dropout_51[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 32, 32, 70)   280         concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 32, 32, 70)   0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 32, 32, 35)   22050       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_52 (Dropout)            (None, 32, 32, 35)   0           conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_49 (Concatenate)    (None, 32, 32, 105)  0           concatenate_48[0][0]             \n",
            "                                                                 dropout_52[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 32, 32, 105)  420         concatenate_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 32, 32, 105)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 32, 32, 35)   33075       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_53 (Dropout)            (None, 32, 32, 35)   0           conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_50 (Concatenate)    (None, 32, 32, 140)  0           concatenate_49[0][0]             \n",
            "                                                                 dropout_53[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 32, 32, 140)  560         concatenate_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 32, 32, 140)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 32, 32, 35)   44100       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_54 (Dropout)            (None, 32, 32, 35)   0           conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 32, 32, 175)  0           concatenate_50[0][0]             \n",
            "                                                                 dropout_54[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 32, 32, 175)  700         concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 32, 32, 175)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 32, 32, 35)   55125       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_55 (Dropout)            (None, 32, 32, 35)   0           conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_52 (Concatenate)    (None, 32, 32, 210)  0           concatenate_51[0][0]             \n",
            "                                                                 dropout_55[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 32, 32, 210)  840         concatenate_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 32, 32, 210)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 32, 32, 35)   66150       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_56 (Dropout)            (None, 32, 32, 35)   0           conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_53 (Concatenate)    (None, 32, 32, 245)  0           concatenate_52[0][0]             \n",
            "                                                                 dropout_56[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 32, 32, 245)  980         concatenate_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 32, 32, 245)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 32, 32, 35)   8575        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_57 (Dropout)            (None, 32, 32, 35)   0           conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 16, 16, 35)   0           dropout_57[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 35)   140         average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 35)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 35)   11025       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_58 (Dropout)            (None, 16, 16, 35)   0           conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_54 (Concatenate)    (None, 16, 16, 70)   0           average_pooling2d_4[0][0]        \n",
            "                                                                 dropout_58[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 70)   280         concatenate_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 70)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 35)   22050       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_59 (Dropout)            (None, 16, 16, 35)   0           conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_55 (Concatenate)    (None, 16, 16, 105)  0           concatenate_54[0][0]             \n",
            "                                                                 dropout_59[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 105)  420         concatenate_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 105)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 35)   33075       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, 16, 16, 35)   0           conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_56 (Concatenate)    (None, 16, 16, 140)  0           concatenate_55[0][0]             \n",
            "                                                                 dropout_60[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 16, 16, 140)  560         concatenate_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 140)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 35)   44100       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_61 (Dropout)            (None, 16, 16, 35)   0           conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_57 (Concatenate)    (None, 16, 16, 175)  0           concatenate_56[0][0]             \n",
            "                                                                 dropout_61[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 16, 16, 175)  700         concatenate_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 175)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 16, 16, 35)   55125       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, 16, 16, 35)   0           conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_58 (Concatenate)    (None, 16, 16, 210)  0           concatenate_57[0][0]             \n",
            "                                                                 dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 16, 16, 210)  840         concatenate_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 16, 16, 210)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 16, 16, 35)   66150       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_63 (Dropout)            (None, 16, 16, 35)   0           conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_59 (Concatenate)    (None, 16, 16, 245)  0           concatenate_58[0][0]             \n",
            "                                                                 dropout_63[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 16, 16, 245)  980         concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 16, 16, 245)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 16, 16, 35)   8575        activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_64 (Dropout)            (None, 16, 16, 35)   0           conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 8, 8, 35)     0           dropout_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 8, 8, 35)     140         average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 8, 8, 35)     0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 8, 8, 35)     11025       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_65 (Dropout)            (None, 8, 8, 35)     0           conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_60 (Concatenate)    (None, 8, 8, 70)     0           average_pooling2d_5[0][0]        \n",
            "                                                                 dropout_65[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 8, 8, 70)     280         concatenate_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 8, 8, 70)     0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 8, 8, 35)     22050       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_66 (Dropout)            (None, 8, 8, 35)     0           conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_61 (Concatenate)    (None, 8, 8, 105)    0           concatenate_60[0][0]             \n",
            "                                                                 dropout_66[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 8, 8, 105)    420         concatenate_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 8, 8, 105)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 8, 8, 35)     33075       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_67 (Dropout)            (None, 8, 8, 35)     0           conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_62 (Concatenate)    (None, 8, 8, 140)    0           concatenate_61[0][0]             \n",
            "                                                                 dropout_67[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 140)    560         concatenate_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 8, 8, 140)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 35)     44100       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_68 (Dropout)            (None, 8, 8, 35)     0           conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_63 (Concatenate)    (None, 8, 8, 175)    0           concatenate_62[0][0]             \n",
            "                                                                 dropout_68[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 8, 8, 175)    700         concatenate_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 8, 8, 175)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 35)     55125       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_69 (Dropout)            (None, 8, 8, 35)     0           conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_64 (Concatenate)    (None, 8, 8, 210)    0           concatenate_63[0][0]             \n",
            "                                                                 dropout_69[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 210)    840         concatenate_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 210)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 8, 8, 35)     66150       activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_70 (Dropout)            (None, 8, 8, 35)     0           conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_65 (Concatenate)    (None, 8, 8, 245)    0           concatenate_64[0][0]             \n",
            "                                                                 dropout_70[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 245)    980         concatenate_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 245)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 8, 8, 35)     8575        activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_71 (Dropout)            (None, 8, 8, 35)     0           conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 4, 4, 35)     0           dropout_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 4, 4, 35)     140         average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 4, 4, 35)     0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 4, 4, 35)     11025       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_72 (Dropout)            (None, 4, 4, 35)     0           conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_66 (Concatenate)    (None, 4, 4, 70)     0           average_pooling2d_6[0][0]        \n",
            "                                                                 dropout_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 4, 4, 70)     280         concatenate_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 4, 4, 70)     0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 4, 4, 35)     22050       activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_73 (Dropout)            (None, 4, 4, 35)     0           conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_67 (Concatenate)    (None, 4, 4, 105)    0           concatenate_66[0][0]             \n",
            "                                                                 dropout_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 4, 4, 105)    420         concatenate_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 4, 4, 105)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 4, 4, 35)     33075       activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_74 (Dropout)            (None, 4, 4, 35)     0           conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_68 (Concatenate)    (None, 4, 4, 140)    0           concatenate_67[0][0]             \n",
            "                                                                 dropout_74[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 4, 4, 140)    560         concatenate_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 4, 4, 140)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 4, 4, 35)     44100       activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_75 (Dropout)            (None, 4, 4, 35)     0           conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_69 (Concatenate)    (None, 4, 4, 175)    0           concatenate_68[0][0]             \n",
            "                                                                 dropout_75[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 4, 4, 175)    700         concatenate_69[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 4, 4, 175)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 4, 4, 35)     55125       activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_76 (Dropout)            (None, 4, 4, 35)     0           conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_70 (Concatenate)    (None, 4, 4, 210)    0           concatenate_69[0][0]             \n",
            "                                                                 dropout_76[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 4, 4, 210)    840         concatenate_70[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 4, 4, 210)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 4, 4, 35)     66150       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_77 (Dropout)            (None, 4, 4, 35)     0           conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_71 (Concatenate)    (None, 4, 4, 245)    0           concatenate_70[0][0]             \n",
            "                                                                 dropout_77[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 4, 4, 245)    980         concatenate_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 4, 4, 245)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 1, 1, 245)    0           activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 1, 1, 10)     2460        average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 10)           0           conv2d_81[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 970,910\n",
            "Trainable params: 963,070\n",
            "Non-trainable params: 7,840\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b4XOsW3ahSkL",
        "colab": {}
      },
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua47eS-3UJU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "generator = ImageDataGenerator(rotation_range=20,\n",
        "                               width_shift_range=0.125,\n",
        "                               height_shift_range=0.125,\n",
        "                               horizontal_flip=True,\n",
        "                               fill_mode='nearest',\n",
        "                               zoom_range=0.10)\n",
        "\n",
        "generator.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muMRfjAOWom6",
        "colab_type": "code",
        "outputId": "e04f7f87-d007-47b3-fd29-140f776186f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "#https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
        "model.fit_generator(generator.flow(X_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=(len(X_train)//batch_size)*5, epochs=20,\n",
        "                    validation_data=(X_test, y_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3905/3905 [==============================] - 410s 105ms/step - loss: 0.4277 - acc: 0.8520 - val_loss: 0.8166 - val_acc: 0.7626\n",
            "Epoch 2/20\n",
            "3905/3905 [==============================] - 406s 104ms/step - loss: 0.3864 - acc: 0.8654 - val_loss: 0.5648 - val_acc: 0.8379\n",
            "Epoch 3/20\n",
            "3905/3905 [==============================] - 409s 105ms/step - loss: 0.3513 - acc: 0.8778 - val_loss: 0.4767 - val_acc: 0.8535\n",
            "Epoch 4/20\n",
            "3905/3905 [==============================] - 409s 105ms/step - loss: 0.3245 - acc: 0.8873 - val_loss: 0.4529 - val_acc: 0.8631\n",
            "Epoch 5/20\n",
            "3905/3905 [==============================] - 407s 104ms/step - loss: 0.3051 - acc: 0.8936 - val_loss: 0.3657 - val_acc: 0.8901\n",
            "Epoch 6/20\n",
            "3905/3905 [==============================] - 406s 104ms/step - loss: 0.2859 - acc: 0.8998 - val_loss: 0.4397 - val_acc: 0.8722\n",
            "Epoch 7/20\n",
            "3905/3905 [==============================] - 407s 104ms/step - loss: 0.2689 - acc: 0.9054 - val_loss: 0.4023 - val_acc: 0.8840\n",
            "Epoch 8/20\n",
            "3905/3905 [==============================] - 402s 103ms/step - loss: 0.2564 - acc: 0.9105 - val_loss: 0.3955 - val_acc: 0.8888\n",
            "Epoch 9/20\n",
            "3905/3905 [==============================] - 400s 103ms/step - loss: 0.2447 - acc: 0.9146 - val_loss: 0.3739 - val_acc: 0.8931\n",
            "Epoch 10/20\n",
            "3905/3905 [==============================] - 400s 102ms/step - loss: 0.2340 - acc: 0.9180 - val_loss: 0.3771 - val_acc: 0.8959\n",
            "Epoch 11/20\n",
            "3905/3905 [==============================] - 400s 103ms/step - loss: 0.2259 - acc: 0.9203 - val_loss: 0.4087 - val_acc: 0.8845\n",
            "Epoch 12/20\n",
            "3905/3905 [==============================] - 401s 103ms/step - loss: 0.2155 - acc: 0.9244 - val_loss: 0.4331 - val_acc: 0.8867\n",
            "Epoch 13/20\n",
            "3905/3905 [==============================] - 400s 102ms/step - loss: 0.2092 - acc: 0.9262 - val_loss: 0.3012 - val_acc: 0.9111\n",
            "Epoch 14/20\n",
            "3905/3905 [==============================] - 400s 102ms/step - loss: 0.2005 - acc: 0.9293 - val_loss: 0.3843 - val_acc: 0.8952\n",
            "Epoch 15/20\n",
            "3905/3905 [==============================] - 399s 102ms/step - loss: 0.1950 - acc: 0.9312 - val_loss: 0.3442 - val_acc: 0.9079\n",
            "Epoch 16/20\n",
            "3905/3905 [==============================] - 400s 102ms/step - loss: 0.1888 - acc: 0.9331 - val_loss: 0.3730 - val_acc: 0.9056\n",
            "Epoch 17/20\n",
            "3905/3905 [==============================] - 400s 102ms/step - loss: 0.1847 - acc: 0.9351 - val_loss: 0.3603 - val_acc: 0.8998\n",
            "Epoch 18/20\n",
            "3905/3905 [==============================] - 400s 102ms/step - loss: 0.1777 - acc: 0.9373 - val_loss: 0.3620 - val_acc: 0.9038\n",
            "Epoch 19/20\n",
            "3905/3905 [==============================] - 400s 103ms/step - loss: 0.1722 - acc: 0.9394 - val_loss: 0.3658 - val_acc: 0.9072\n",
            "Epoch 20/20\n",
            "3905/3905 [==============================] - 400s 102ms/step - loss: 0.1679 - acc: 0.9407 - val_loss: 0.3436 - val_acc: 0.9071\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb431f2aac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZcWydmIVhZGr",
        "outputId": "7bcec649-fe80-4e84-9373-2cd6e29f9879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Test the model\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 444us/sample - loss: 0.3447 - acc: 0.9071\n",
            "Test loss: 0.3446852895885706\n",
            "Test accuracy: 0.9071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UE3lF6EH1r_L",
        "outputId": "532ecad4-0914-49a7-c550-ec48e88c38ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu-RGAZB3S7B",
        "colab_type": "text"
      },
      "source": [
        "#Conclusions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZL0eYTi6oVa",
        "colab_type": "text"
      },
      "source": [
        "1- Used the given densenet to build the architecture of the model.\n",
        "\n",
        "2- Used Image Augmentation techniques to make the model robust.\n",
        "\n",
        "3- Used adam optimizer to optimize the loss.\n",
        "\n",
        "4- Run the code for 20 epochs.\n",
        "\n",
        "5- Test Loss=0.344\n",
        "\n",
        "6- Test accuracy=90.71%"
      ]
    }
  ]
}